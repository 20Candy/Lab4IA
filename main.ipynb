{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labarotorio 4 Inteligencia Artificial "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion Lineal Polinomica\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leer archvivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajustar Modelo Polinomial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar los datos y almacenarlos en una matriz de NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.genfromtxt('kc_house_data.csv', delimiter=',', skip_header=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar los datos de la variable objetivo (price) y la variable predictora (sqft living)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[:, 2]  # price\n",
    "X = data[:, 5]  # sqft living"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregar una columna de unos a la matriz de la variable predictora para representar el término de intercepción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([X, np.ones(len(X))]).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizar la fórmula matricial de mínimos cuadrados para ajustar el modelo lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.linalg.inv(X.T @ X) @ X.T @ y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizar el modelo ajustado para hacer predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[377354.6087517  517666.39270042]\n"
     ]
    }
   ],
   "source": [
    "new_X = np.array([1500, 2000])  # ejemplos de nuevos valores de sqft living\n",
    "new_X = np.vstack([new_X, np.ones(len(new_X))]).T\n",
    "predictions = new_X @ theta\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacion Vectorial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar los datos desde el archivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def load_data(file_path, delimiter=\",\"):\n",
    "    data = []\n",
    "    with open(file_path) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=delimiter)\n",
    "        for row in csv_reader:\n",
    "            data.append(row)\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir los datos a una matriz de numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_matrix(data, target_col, feature_cols):\n",
    "    data = np.array(data[1:], dtype=float)[:, 1:] # Omitir la primera columna y la fila de encabezados\n",
    "    X = data[:, feature_cols]\n",
    "    y = data[:, target_col]\n",
    "    return X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    X_norm = (X - mean) / std\n",
    "    return X_norm, mean, std"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular el costo (error) del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, theta):\n",
    "    m = len(y)\n",
    "    h = X.dot(theta)\n",
    "    cost = np.sum((h - y) ** 2) / (2 * m)\n",
    "    return cost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementar el descenso de gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, alpha, num_iters):\n",
    "    m = len(y)\n",
    "    J_history = np.zeros(num_iters)\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        h = X.dot(theta)\n",
    "        error = h - y\n",
    "        grad = X.T.dot(error) / m\n",
    "        theta -= alpha * grad\n",
    "        J_history[i] = compute_cost(X, y, theta)\n",
    "\n",
    "    return theta, J_history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '20141013T000000'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m target_col \u001b[39m=\u001b[39m [\u001b[39m2\u001b[39m] \u001b[39m# price\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m# Convertir los datos a una matriz de numpy\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m X, y \u001b[39m=\u001b[39m data_to_matrix(data, target_col, feature_cols)\n\u001b[0;32m     11\u001b[0m \u001b[39m# Normalizar los datos\u001b[39;00m\n\u001b[0;32m     12\u001b[0m X, mean, std \u001b[39m=\u001b[39m normalize(X)\n",
      "Cell \u001b[1;32mIn[57], line 2\u001b[0m, in \u001b[0;36mdata_to_matrix\u001b[1;34m(data, target_col, feature_cols)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdata_to_matrix\u001b[39m(data, target_col, feature_cols):\n\u001b[1;32m----> 2\u001b[0m     data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(data[\u001b[39m1\u001b[39;49m:], dtype\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m)[:, \u001b[39m1\u001b[39m:] \u001b[39m# Omitir la primera columna y la fila de encabezados\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     X \u001b[39m=\u001b[39m data[:, feature_cols]\n\u001b[0;32m      4\u001b[0m     y \u001b[39m=\u001b[39m data[:, target_col]\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '20141013T000000'"
     ]
    }
   ],
   "source": [
    "# Cargar los datos desde el archivo\n",
    "data = load_data(\"kc_house_data.csv\")\n",
    "\n",
    "# Definir las columnas que se utilizarán como características (features) y etiquetas (target)\n",
    "feature_cols = [5] # sqft_living\n",
    "target_col = [2] # price\n",
    "\n",
    "# Convertir los datos a una matriz de numpy\n",
    "X, y = data_to_matrix(data, target_col, feature_cols)\n",
    "\n",
    "# Normalizar los datos\n",
    "X, mean, std = normalize(X)\n",
    "\n",
    "# Añadir una columna de unos a la matriz X para el término de sesgo (bias)\n",
    "X = np.hstack((np.ones((len(y), 1)), X))\n",
    "\n",
    "# Inicializar los pesos aleatoriamente\n",
    "theta = np.random.rand(X.shape[1])\n",
    "\n",
    "# Definir los hiperparámetros del algoritmo de gradiente descendente\n",
    "alpha = 0.1\n",
    "num_iters = 1000\n",
    "\n",
    "# Ejecutar el algoritmo de gradiente descendente\n",
    "theta, J_history = gradient_descent(X, y, theta, alpha, num_iters)\n",
    "\n",
    "# Imprimir los pesos del modelo\n",
    "print(\"Pesos del modelo:\", theta)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_iters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39mplot(\u001b[39mrange\u001b[39m(num_iters), J_history)\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m\"\u001b[39m\u001b[39mIteraciones\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m\"\u001b[39m\u001b[39mCosto (error)\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_iters' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(num_iters), J_history)\n",
    "plt.xlabel(\"Iteraciones\")\n",
    "plt.ylabel(\"Costo (error)\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uso de Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de entrenamiento promedio:  nan\n",
      "Error de prueba promedio:  nan\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cross_validate(X, y, k=5):\n",
    "    \"\"\"\n",
    "    Divide los datos en k partes y realiza k iteraciones del cross-validation.\n",
    "    En cada iteración, una de las partes se usa como conjunto de prueba y el resto\n",
    "    como conjunto de entrenamiento. Retorna los errores de entrenamiento y prueba\n",
    "    para cada iteración.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    indices = np.arange(n)\n",
    "    np.random.shuffle(indices)\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "    split_size = n // k\n",
    "    train_errors = np.zeros(k)\n",
    "    test_errors = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        test_indices = np.arange(i*split_size, (i+1)*split_size)\n",
    "        train_indices = np.concatenate((np.arange(0, i*split_size), np.arange((i+1)*split_size, n)))\n",
    "        X_train = X[train_indices]\n",
    "        y_train = y[train_indices]\n",
    "        X_test = X[test_indices]\n",
    "        y_test = y[test_indices]\n",
    "        # Entrenar el modelo con los datos de entrenamiento\n",
    "        weights = fit_polynomial_regression(X_train, y_train)\n",
    "        # Calcular los errores de entrenamiento y prueba\n",
    "        train_errors[i] = calculate_error(X_train, y_train, weights)\n",
    "        test_errors[i] = calculate_error(X_test, y_test, weights)\n",
    "    return train_errors, test_errors\n",
    "\n",
    "def fit_polynomial_regression(X, y, degree=1):\n",
    "    \"\"\"\n",
    "    Entrena un modelo de regresión polinomial de grado \"degree\" utilizando\n",
    "    los datos de entrada X y los valores objetivo y. Retorna los pesos\n",
    "    (coeficientes) de la regresión.\n",
    "    \"\"\"\n",
    "    X_poly = polynomial_features(X, degree)\n",
    "    X_poly_T = np.transpose(X_poly)\n",
    "    weights = np.linalg.inv(X_poly_T @ X_poly) @ (X_poly_T @ y)\n",
    "    return weights\n",
    "\n",
    "def polynomial_features(X, degree=1):\n",
    "    \"\"\"\n",
    "    Expande los datos de entrada X para incluir todas las potencias de grado\n",
    "    hasta el grado \"degree\". Retorna una nueva matriz con las características\n",
    "    expandidas.\n",
    "    \"\"\"\n",
    "    X_poly = X.copy()\n",
    "    for i in range(2, degree+1):\n",
    "        X_poly = np.column_stack((X_poly, np.power(X, i)))\n",
    "    return X_poly\n",
    "\n",
    "def calculate_error(X, y, weights):\n",
    "    \"\"\"\n",
    "    Calcula el error cuadrático medio para un modelo de regresión y los datos\n",
    "    de entrada y los valores objetivo. Retorna el error.\n",
    "    \"\"\"\n",
    "    y_pred = predict(X, weights)\n",
    "    error = np.mean((y - y_pred)**2)\n",
    "    return error\n",
    "\n",
    "def predict(X, weights):\n",
    "    \"\"\"\n",
    "    Calcula las predicciones de un modelo de regresión para los datos de entrada\n",
    "    X utilizando los pesos (coeficientes) dados. Retorna las predicciones.\n",
    "    \"\"\"\n",
    "    return X @ weights\n",
    "\n",
    "def split_data(X, y, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Divide los datos de entrada X y los valores objetivo y en conjuntos de entrenamiento\n",
    "    y prueba, utilizando el ratio especificado. Retorna los conjuntos de entrenamiento y\n",
    "    prueba.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    train_size = int(train_ratio * n)\n",
    "    indices = np.arange(n)\n",
    "    np.random.shuffle(indices)\n",
    "    train_indices = indices[:train_size]\n",
    "    test_indices = indices[train_size:]\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Cargar los datos\n",
    "data = np.genfromtxt('kc_house_data.csv', delimiter=',', skip_header=True)\n",
    "feature_cols = [0]\n",
    "target_col = [1]\n",
    "\n",
    "# Convertir los datos a una matriz de numpy\n",
    "X, y = data_to_matrix(data, target_col, feature_cols)\n",
    "\n",
    "# Normalizar los datos\n",
    "X, mean, std = normalize(X)\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, y_train, X_test, y_test = split_data(X, y, train_ratio=0.8)\n",
    "\n",
    "# Realizar cross-validation con los datos de entrenamiento\n",
    "train_errors, test_errors = cross_validate(X_train, y_train, k=5)\n",
    "\n",
    "# Calcular los errores promedio de entrenamiento y prueba\n",
    "mean_train_error = np.mean(train_errors)\n",
    "mean_test_error = np.mean(test_errors)\n",
    "\n",
    "print(\"Error de entrenamiento promedio: \", mean_train_error)\n",
    "print(\"Error de prueba promedio: \", mean_test_error)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "807176c006fb8bacbb9425be13c91e6bbd3ac320bebb29758cc8b3e8695260f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
